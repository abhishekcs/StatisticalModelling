\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}

\usetikzlibrary{automata,positioning}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{\hmwkClass\ (\hmwkClassInstructor): \hmwkTitle}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
        \setcounter{homeworkProblemCounter}{#1}
    \fi
    \section{Problem \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}

%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework\ \#1}
\newcommand{\hmwkClass}{Statistical Modelling 2}
\newcommand{\hmwkClassInstructor}{Professor James Scott}
\newcommand{\hmwkAuthorName}{\textbf{Abhishek Sinha}}

%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
    \vspace{3in}
}

\author{\hmwkAuthorName}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}

% Probability commands: Expectation, Variance, Covariance, Bias
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}

\begin{document}

\maketitle

\pagebreak

\begin{homeworkProblem}
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
\textbf{Part A} \\
    \[
        \begin{split}
            cov(x) &= E\{(x-\mu)(x-\mu)^T\}
            \\
            &= E\{(x-\mu)(x^T-\mu^T)\} , \textrm{using property of transpose}
            \\
            &= E\{xx^T - x\mu^T - \mu x^T + \mu\mu^T\} , \textrm{using distributive property of matrix multiplication}
            \\
            &= E(xx^T )- E(x\mu^T )- E(\mu x^T) + E(\mu\mu^T), \textrm{using Linearity of Expectation }
            \\
            &= E(xx^T) - E(x)\mu^T - \mu E(x^T) + \mu\mu^T, \textrm{$\mu$ being a constant can be pushed out of the expectation}
            \\
            &= E(xx^T) - \mu\mu^T - \mu\mu^T + \mu\mu^T
            \\
            &= E(xx^T) - \mu\mu^T
        \end{split}
    \]
    
        \[
        \begin{split}
            cov(Ax + b) &= E\{(Ax+b)(Ax + b)^T\} - E(Ax+b)E(Ax+b)^T, \textrm{using previous result}
            \\
            &= E\{(Ax+b)(x^TA^T + b^T)\} - \{E(Ax) + b\}\{E(Ax)+b\}^T, \textrm{using property of transpose}
            \\
            &\stackrel{1}{=} E(Axx^TA^T) + E(Axb^T) + E(bx^TA^T) + E(bb^T) - (A\mu + b)(A\mu + b)^T
            \\
           &\stackrel{2}{=} AE(xx^T)A^T + AE(x)b^T + bE(x^T)A^T + bb^T - (A\mu+b)(\mu^TA^T + b^T)
           \\
            &\stackrel{3}{=} AE(xx^T)A^T + A\mu b^T + b \mu^TA^T + bb^T - A\mu\mu^TA^T - A\mu b^T - b\mu^TA^T - bb^T            	    \\
            &= AE(xx^T)A^T - A\mu\mu^TA^T
            \\
            &=  Acov(x)A^T, \textrm{using previous result}
        \end{split}
    \]
    
 1 follows from linearity of expectation and distributive property of matrix multiplication. 2 follows from the fact that $A$ and $\mu$ being constants can be pushed out of the expectation. 3 follows from the definition of $\mu$
 
 \par
\textbf{Part D}\\
Let us try to find the moment generating function for the random variable z.
        \[
        \begin{split}
            {MGF}_{x}(t) &= E\{\exp(t^Tx)\}, \textrm{using definition of MGF}
            \\
            &= E\{\exp(t^T(Lz + \mu))\}, \textrm{substituting for $x$ in terms of $z$}
            \\
            &= E\{\exp(t^TLz)\} E\{\exp(t^T\mu)\}, \textrm{distributing the powers}
            \\
            &= E\{\exp(t^TLz)\} \exp(t^T\mu), \textrm{$t^T\mu$ is constant for a given $t$}
            \\
            &= E\{\exp((L^Tt)^Tz)\} \exp(t^T\mu), \textrm{using basic property of transpose}
            \\
            &= \exp( (L^Tt)^TI(L^Tt)) \exp(t^T \mu), \textrm{using MGF for standard multivariate normal}
            \\
            &= \exp(t^TLL^Tt)\exp(t^T\mu)
            \\
            &= \exp(t^T\mu + t^T(LL^T)t), \textrm{combining the powers}
        \end{split}
    \]
Now using the if part of the result in part C, we can easily see that $x \sim N(u, LL^T)$
\par
\par

\textbf{Part E} \\
Suppose $x \sim N(\mu, \Sigma)$. We know that the matrix $\Sigma$ is symmetric since for any $i,j$ we have that $cov(x_i, x_j) = cov(x_j, x_i)$. From the spectral theorem, there exists an orthonormal matrix $U$ and a diagonal matrix $D$ such that $\Sigma = UDU^T$. We can rewrite this decomposition as $\Sigma = UD^{\frac{1}{2}}(UD^{\frac{1}{2}} )^T$ where $D^{\frac{1}{2}}$ is the matrix obtained by taking the square roots of the the diagonal entries of $D$.
\end{homeworkProblem}

\begin{homeworkProblem}
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
\end{homeworkProblem}

\pagebreak

%
% Non sequential homework problems
%

% Jump to problem 18
\begin{homeworkProblem}[18]
\end{homeworkProblem}

% Continue counting to 19
\begin{homeworkProblem}
\end{homeworkProblem}

% Go back to where we left off
\begin{homeworkProblem}[6]
\end{homeworkProblem}

\end{document}